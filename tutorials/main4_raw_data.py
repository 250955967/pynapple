#!/usr/bin/env python

'''
	File name: main4_raw_data.py
	Author: Guillaume Viejo
	Date created: 13/10/2017    
	Python Version: 3.5.2

This scripts will show you how to use the wrappers function to load raw data
A typical preprocessing pipeline shall output 
	- Mouse-Session.clu.*
	- Mouse-Session.res.*
	- Mouse-Session.fet.*
	- Mouse-Session.spk.*
	- Mouse-Session.xml
	- Mouse-Session.eeg
	- Epoch_TS.csv
	- Mouse-Session_*.csv
	- Mouse-Session_*_analogin.dat



The data should be found in StarterPack/data_raw/KA28-190405

This script will show you how to load the various data you need

The function are already written in the file wrappers.py that should be in the same directory as this script

To speed up loading of the data, a folder called /Analysis will be created and some data will be saved here
So that next time, you load the script, the wrappers will search in /Analysis to load faster
'''

import numpy as np
import pandas as pd
import pynapple as ap
from pylab import *

# first we define a string for the data directory
# It is usually better to separate the data from the code
data_directory = '../data/A2929-200711'
# The two dots means we go backward in the folder architecture and then into the data folder


# To list the files in the directory, you use the os package (for Operating System) and the listdir function
import os
files = os.listdir(data_directory) 
# Check your variables by typing files in your terminal
files

# First thing to load are the spikes.
# Here you can use the wrappers loadSpikeData
spikes, shank = ap.loadSpikeData(data_directory)
# Type your variables in the terminal to see what it looks like

# Second thing is some information about the recording session like the geometry of the shanks and sampling frequency
# You can use the loadXML wrapper
n_channels, fs, shank_to_channel = ap.loadXML(data_directory)
# Again type your variables

# Now we want to load the position of the animal
# In the data folder, observe that you have a file called Epoch_TS.csv which contains the start and end of the different epoch
# This file is automatically generated by the kilosort preprocessing pipeline
# One thing to know is what was the structure of the recording day
# In this case, sleep alternate with wake
# So you define the episode keys and the index of the events for wake

episodes = ['sleep', 'wake']
events = ['1']

# Now we can load the position and rotation contained into the file Tracking_data.csv
# The order is by default [rotation y, rotation x, rotation z, position x, position y, position z]
position = ap.loadPosition(data_directory, events, episodes)

# The loadPosition is doing of lot of stuff in the background
# in particular it's making a BehavEpoch.h5 in the folder analysis
# It contains the start and end of all the epochs
# plus it's automatically realigning the start and end of the wake epoch to the start and end of the tracking

# But now, you can load the different epoch 
wake_ep 							= ap.loadEpoch(data_directory, 'wake', episodes)
sleep_ep 							= ap.loadEpoch(data_directory, 'sleep')					


# We can look at the position of the animal in 2d with a figure
figure()
plot(position['x'], position['z'])
show()


# Now we are going to compute the tuning curve for all neurons during exploration
# The process of making a tuning curve has been covered in main3_tuningcurves.py
# So here we are gonna use the function computeAngularTuningCurves from functions.py 
tuning_curves = ap.computeAngularTuningCurves(spikes, position['ry'], wake_ep, 60)

	
# And let's plot all the tuning curves in a polar plot
from pylab import *
figure()
for i, n in enumerate(tuning_curves.columns):
	subplot(5,5,i+1, projection = 'polar')
	plot(tuning_curves[n])	
show()


# It's a bit dirty. Let's smooth the tuning curves ...
tuning_curves = ap.smoothAngularTuningCurves(tuning_curves, 10, 2)

# and plot it again
figure()
for i, n in enumerate(tuning_curves.columns):
	subplot(5,5,i+1, projection = 'polar')
	plot(tuning_curves[n])	
show()
